{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing as mp\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_score,accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import datafiles to generate train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_file = '../data/enz_sequence.csv'\n",
    "label_file = '../data/enz_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(seq_file,header=None)\n",
    "df2 = pd.read_csv(label_file,header=None)\n",
    "df = df1.merge(df2,on=0)\n",
    "\n",
    "def filter_by_len(seq):\n",
    "    val = len(seq)\n",
    "    if val>200 and val<600:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "df = df.loc[df['1_x'].apply(filter_by_len)]\n",
    "# create a smaller test-train\n",
    "df_0 = df.loc[df.iloc[:,-1]==0]\n",
    "df_1 = df.loc[df.iloc[:,-1]==1]\n",
    "train_df0 = df_0.sample(n=int(0.75*(len(df_0))),random_state=17)\n",
    "valid_df0 = df_0.loc[~df_0.isin(train_df0)[0]]\n",
    "train_df1 = df_1.sample(n=int(0.6*(len(df_1))),random_state=17)\n",
    "valid_df1 = df_1.loc[~df_1.isin(train_df1)[0]]\n",
    "train_df = pd.concat([train_df0,train_df1])\n",
    "valid_df = pd.concat([valid_df0,valid_df1])\n",
    "train_df = train_df.sample(frac=1,random_state=17)\n",
    "valid_df = valid_df.sample(frac=1,random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self,X_train,X_valid,X_test,y_train,y_valid,y_test,feat_vec):\n",
    "        \n",
    "        self.X_train,self.X_valid,self.X_test,self.y_train,self.y_valid,self.y_test = X_train,X_valid,X_test,y_train,y_valid,y_test\n",
    "        \n",
    "        pattern = re.compile('.+/+(.+)\\.csv\\.gz$')\n",
    "        m = re.match(pattern,feat_vec)\n",
    "        featname = m.group(1)\n",
    "        \n",
    "        filename = '../data/simResults/ind_feat_results/'+featname+'.log'\n",
    "        \n",
    "        with open(filename,'w') as f:\n",
    "            f.write('-'*5 + featname + ' model evaluation begins' + '-'*5 + '\\n')\n",
    "            \n",
    "    \n",
    "        pool = mp.Pool(mp.cpu_count())\n",
    "        depths = [10,14,19,21,25,55]\n",
    "        scrs = list(pool.map(self.get_score_dt,depths))\n",
    "        self.dtclf = self.dt_clf(depths[np.argmax(scrs)])\n",
    "        with open(filename,'a') as f:\n",
    "            f.write('\\n')\n",
    "            f.write('Decision Tree Stats'+'\\n')\n",
    "            f.write('\\n')\n",
    "        self.write_clf_stats(self.dtclf,filename)\n",
    "            \n",
    "        pool = mp.Pool(mp.cpu_count())\n",
    "        c_param = [1,1.25,1.5,3,5,7,10,20,25,35,100]\n",
    "        scrs = list(pool.map(self.get_score_svc,c_param))            \n",
    "        self.svcclf = self.svc_clf(c_param[np.argmax(scrs)])\n",
    "        with open(filename,'a') as f:\n",
    "            f.write('\\n')\n",
    "            f.write('SVM Stats'+'\\n')\n",
    "            f.write('\\n')\n",
    "        self.write_clf_stats(self.svcclf,filename)\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def dt_clf(self,max_depth):\n",
    "        dt = DecisionTreeClassifier(max_features='auto',\n",
    "                                    max_depth=max_depth,random_state=42)\n",
    "        steps = [('scaler',StandardScaler()),('dt',dt)]\n",
    "        pipe = Pipeline(steps)\n",
    "        pipe.fit(self.X_train,self.y_train)\n",
    "        return pipe\n",
    "\n",
    "    def get_score_dt(self,max_depth):\n",
    "        p = self.dt_clf(max_depth)\n",
    "        return p.score(self.X_valid,self.y_valid)\n",
    "\n",
    "    def svc_clf(self,regC):\n",
    "        svc = SVC(C = regC,\n",
    "                kernel='rbf',\n",
    "                decision_function_shape='ovo',\n",
    "                random_state=42,\n",
    "                class_weight=None)\n",
    "        steps = [('scaler',StandardScaler()),('svc',svc)]\n",
    "        pipe = Pipeline(steps)\n",
    "        pipe.fit(self.X_train,self.y_train)\n",
    "        return pipe\n",
    "\n",
    "    def get_score_svc(self,regC):\n",
    "        p = self.svc_clf(regC)\n",
    "        return p.score(self.X_valid,self.y_valid)\n",
    "    \n",
    "    def getHPOPTfigure(d,s):\n",
    "        plt.plot(d,s)\n",
    "        return\n",
    "    \n",
    "    def get_uniqcount(self,arr):\n",
    "        return np.unique(arr,return_counts=True)\n",
    "    \n",
    "    def write_clf_stats(self,clf,filename):\n",
    "        \n",
    "        yhattrain = clf.predict(self.X_train)\n",
    "        yhatvalid = clf.predict(self.X_valid)\n",
    "        yhattest = clf.predict(self.X_test)\n",
    "        acc_train = accuracy_score(self.y_train,yhattrain)\n",
    "        prec_train = precision_score(self.y_train,yhattrain,pos_label=0)\n",
    "        acc_valid = accuracy_score(self.y_valid,yhatvalid)\n",
    "        prec_valid = precision_score(self.y_valid,yhatvalid,pos_label=0)\n",
    "        acc_test = accuracy_score(self.y_test,yhattest)\n",
    "        prec_test = precision_score(self.y_test,yhattest,pos_label=0)\n",
    "        \n",
    "        with open(filename,'a') as f:\n",
    "            f.write('Training Data Label Count\\n')\n",
    "            for i,j in zip(*self.get_uniqcount(self.y_train)):\n",
    "                f.write(str(i)+':'+str(j))\n",
    "                f.write('\\n')\n",
    "            f.write('Train Accuracy: '+str(acc_train)+'\\n')\n",
    "            f.write('Train Precision: '+str(prec_train)+'\\n')\n",
    "            f.write('Validation Data Label Count\\n')\n",
    "            for i,j in zip(*self.get_uniqcount(self.y_valid)):\n",
    "                f.write(str(i)+':'+str(j))\n",
    "                f.write('\\n')\n",
    "            f.write('Validation Accuracy: '+str(acc_valid)+'\\n')\n",
    "            f.write('Validation Precision: '+str(prec_valid)+'\\n')\n",
    "            f.write('Test Data Label Count\\n')\n",
    "            for i,j in zip(*self.get_uniqcount(self.y_test)):\n",
    "                f.write(str(i)+':'+str(j))\n",
    "                f.write('\\n')\n",
    "            f.write('Test Accuracy: '+str(acc_test)+'\\n')\n",
    "            f.write('Test Precision: '+str(prec_test)+'\\n')\n",
    "            \n",
    "        return \n",
    "    \n",
    "    \n",
    "class Feat_Evaluation(Classifier):\n",
    "    def __init__(self,feat_vec_file):\n",
    "        feat_vec = feat_vec_file\n",
    "        feat_df1 = pd.read_csv(feat_vec,header=None)\n",
    "        feat_df2 = pd.read_csv(label_file,header=None)\n",
    "        feat_df = feat_df1.merge(feat_df2,on=0)\n",
    "\n",
    "        train_featdf = feat_df.loc[feat_df[0].isin(train_df[0].values)]\n",
    "        valid_featdf = feat_df.loc[feat_df[0].isin(valid_df[0].values)]\n",
    "\n",
    "        #define data\n",
    "        testenz_names = valid_featdf.iloc[:,0].values\n",
    "        X_test = valid_featdf.iloc[:,1:-1].values\n",
    "        y_test = valid_featdf.iloc[:,-1].values\n",
    "\n",
    "        #define data\n",
    "        enz_names = train_featdf.iloc[:,0].values\n",
    "        X = train_featdf.iloc[:,1:-1].values\n",
    "        y = train_featdf.iloc[:,-1].values\n",
    "\n",
    "        # train test split\n",
    "        X_train, X_valid, y_train, y_valid, enz_train, enz_valid = train_test_split(X, y, enz_names, \n",
    "                                test_size=0.1, random_state=17)\n",
    "        \n",
    "        super().__init__(X_train, X_valid, X_test, y_train, y_valid,y_test,feat_vec_file)\n",
    "        \n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_eval_func(featfile):\n",
    "    feat_eval = Feat_Evaluation(featfile)\n",
    "    return \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [17:13<00:00, 24.61s/it]\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    ifeatdir = '../featEngg/offline/ifeatMethods/data/featvec/trainfiles/'\n",
    "    pssmdir = '../featEngg/offline/pssmMethods/data/featvec/trainfiles/'\n",
    "    feat_vecfiles = [ifeatdir + f.name for f in os.scandir(ifeatdir) if f.name.endswith('.csv.gz')]\n",
    "    pssm_vecfiles = [pssmdir + f.name for f in os.scandir(pssmdir) if f.name.endswith('.csv.gz')]\n",
    "    feat_vecfiles.extend(pssm_vecfiles)\n",
    "\n",
    "    for i in tqdm.tqdm(range(len(feat_vecfiles))):\n",
    "        feat_eval_func(feat_vecfiles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
