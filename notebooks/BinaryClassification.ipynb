{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import tqdm\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "sys.path.append('../')\n",
    "from ensemble.model import Ensemble\n",
    "from baseModels.SVM.model import SVM\n",
    "from baseModels.GBC.model import GBC\n",
    "from baseModels.NN.model import NN\n",
    "from featEngg.online.kmerMethods.models import ngModel,gaangModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base:\n",
    "    def __init__(self,SVM=True,GBC=False,NN=False,pca_components=55,regCparam=5,\n",
    "        kernparam='rbf',nestparam=300,lrateparam=0.005,mdepthparam=5,ssampleparam=1,hlayer=(100,50,10),\n",
    "        lrateinit=0.01,regparam=0.005,random_seed=None,optimizeQ=False,verboseQ=False):\n",
    "        \n",
    "        self.pca_components=pca_components\n",
    "        self.optimizeQ=optimizeQ\n",
    "        self.verboseQ=verboseQ\n",
    "        self.rs=random_seed\n",
    "        \n",
    "        if SVM:\n",
    "            self.regCparam=regCparam\n",
    "            self.kernparam=kernparam\n",
    "            \n",
    "        elif GBC:\n",
    "            self.nestparam=nestparam\n",
    "            self.lrateparam=lrateparam\n",
    "            self.mdepthparam=mdepthparam\n",
    "\n",
    "\n",
    "        elif NN:\n",
    "            self.hlayer=hlayer\n",
    "            self.lrateparam=lrateinit\n",
    "            self.reg=regparam\n",
    "\n",
    "            \n",
    "        else:\n",
    "            raise ValueError('No model initiated')\n",
    "            \n",
    "    def get_SVM(self,Xtrain,Xvalid,ytrain,yvalid,Xtest=None):\n",
    "        return SVM(Xtrain,Xvalid,ytrain,yvalid,Xtest,pca_comp=self.pca_components,regC=self.regCparam,kern=self.kernparam,optimize=self.optimizeQ,verbose=self.verboseQ,random_seed=self.rs,classweight=None)\n",
    "    \n",
    "    def get_GBC(self,Xtrain,Xvalid,ytrain,yvalid,Xtest=None):\n",
    "        return GBC(Xtrain,Xvalid,ytrain,yvalid,Xtest,pca_comp=self.pca_components,nest=self.nestparam,lrate=self.lrateparam,mdepth=self.mdepthparam,optimize=self.optimizeQ,verbose=self.verboseQ,random_seed=self.rs)\n",
    "\n",
    "    def get_NN(self,Xtrain,Xvalid,ytrain,yvalid,Xtest=None):\n",
    "        return NN(Xtrain,Xvalid,ytrain,yvalid,Xtest,pca_comp=self.pca_components,hlayers=self.hlayer,lrateinit=self.lrateparam,regparam=self.reg,optimize=self.optimizeQ,verbose=self.verboseQ,random_seed=self.rs)\n",
    "\n",
    "\n",
    "class EClassification(Base):\n",
    "    \n",
    "    def __init__(self,enzseqdata,testenzseqdata,labelfile,trainfeaturefiledirs,testfeaturefiledirs,model='SVM',random_seed=None,pca_components=55,n_models=17,validation_fraction=0.25):\n",
    "        \n",
    "        self.random_seed = random_seed\n",
    "        self.model=model\n",
    "        self.default_pca_components = pca_components\n",
    "        self.n_models = n_models\n",
    "        self.validation_fraction = validation_fraction\n",
    "        self.test = True if testfeaturefiledirs else False\n",
    "        \n",
    "        \n",
    "        #initialize super class\n",
    "        if self.model=='SVM':\n",
    "            super().__init__(optimizeQ=False)\n",
    "        else:\n",
    "            if self.model=='GBC':\n",
    "                super().__init__(SVM=False,GBC=True)\n",
    "            elif self.model=='NN':\n",
    "                super().__init__(SVM=False,NN=True)\n",
    "            else:\n",
    "                raise ValueError('Wrong Model Assigned')\n",
    "        \n",
    "        self.object_map = {'SVM':self.get_SVM,'NN':self.get_NN,'GBC':self.get_GBC}\n",
    "        \n",
    "        # original data based on which everything is obtained\n",
    "        df1 = pd.read_csv(enzseqdata,header=None)\n",
    "        df2 = pd.read_csv(labelfile,header=None)\n",
    "        self.train_df = df1.merge(df2,on=0)\n",
    "        \n",
    "        self.enz_names = self.train_df[0].values\n",
    "        self.X = self.train_df.iloc[:,1].values\n",
    "        self.y = self.train_df.iloc[:,-1].values\n",
    "        \n",
    "        # training and validation data for general use\n",
    "        self.X_train, self.X_valid, self.y_train, self.y_valid,self.enz_train,self.enz_valid = train_test_split(self.X, self.y,self.enz_names, test_size=self.validation_fraction, random_state=self.random_seed)\n",
    "        \n",
    "        self.label_file = labelfile\n",
    "        \n",
    "        # test data\n",
    "        if self.test:\n",
    "            self.test_df = pd.read_csv(testenzseqdata,header=None)\n",
    "            self.testenz_names = self.test_df[0].values\n",
    "            self.X_test = self.test_df.iloc[:,1].values\n",
    "        else:\n",
    "            self.X_test=None\n",
    "        \n",
    "        self.make_tempdir()\n",
    "            \n",
    "        # kmer and gaakmer\n",
    "        ng = ngModel(self.X_train,self.X_valid,self.X_test)\n",
    "        gaang = gaangModel(self.X_train,self.X_valid,self.X_test)\n",
    "        kmernames = ['kmer','gaakmer']\n",
    "        kmerObjs = [self.get_model_online(ng.Xtrain,ng.Xvalid,self.y_train,self.y_valid,ng.Xtest),self.get_model_online(gaang.Xtrain,gaang.Xvalid,self.y_train,self.y_valid,gaang.Xtest)]\n",
    "\n",
    "        \n",
    "        #generate a list of names from the directories\n",
    "        trainfeatfiles = [d+f.name for d in trainfeaturefiledirs for f in os.scandir(d) if f.name.endswith('.csv.gz')]            \n",
    "        self.featnames = [f.name.replace('.csv.gz','') for d in trainfeaturefiledirs for f in os.scandir(d) if f.name.endswith('.csv.gz')]\n",
    "        \n",
    "        feat_pool = mp.Pool(mp.cpu_count())\n",
    "        if self.test:\n",
    "            testfeatfiles = [d+f.name for d in testfeaturefiledirs for f in os.scandir(d) if f.name.endswith('.csv.gz')]\n",
    "            func_iter = list(zip(trainfeatfiles,testfeatfiles))\n",
    "            assert [f.name for d in trainfeaturefiledirs for f in os.scandir(d) if f.name.endswith('.csv.gz')]==[f.name for d in testfeaturefiledirs for f in os.scandir(d) if f.name.endswith('.csv.gz')]\n",
    "            self.objects=list(itertools.starmap(self.get_model_offline,func_iter))\n",
    "\n",
    "        else:\n",
    "            # getting all objects together\n",
    "            self.objects = list(feat_pool.map(self.get_model_offline,trainfeatfiles))\n",
    "            \n",
    "        self.featnames.extend(kmernames)\n",
    "        self.objects.extend(kmerObjs)\n",
    "            \n",
    "        \n",
    "        # select only the best models based on training or validation\n",
    "        self.best_idx,self.best_models = self.select_top_models(self.objects)\n",
    "        self.best_model_names = np.array(self.featnames)[self.best_idx]\n",
    "        \n",
    "        # getting all model predictions together for ensemble\n",
    "        if not self.test:\n",
    "            self.all_model_preds = [o.ypredvalid for o in self.best_models]\n",
    "            self.en = Ensemble(self.all_model_preds,self.y_valid)\n",
    "            self.precision = precision_score(self.y_valid,self.en.preds,pos_label=0,average='binary')\n",
    "            \n",
    "        else:\n",
    "            self.all_model_preds = [o.yhattest for o in self.best_models]\n",
    "            self.en = Ensemble(self.all_model_preds)\n",
    "        \n",
    "        self.del_dir()\n",
    "        pass\n",
    "    \n",
    "    def make_tempdir(self):\n",
    "        !mkdir -p tmp\n",
    "        return \n",
    "    \n",
    "    def write_model_stats(self,featname,obj):\n",
    "        with open('tmp/'+featname+'.txt','w') as f:\n",
    "            f.write(str(obj.acc_train))\n",
    "            f.write('\\n')\n",
    "            f.write(str(obj.acc_valid))\n",
    "            f.write('\\n')\n",
    "        return\n",
    "    \n",
    "    def del_dir(self):\n",
    "        !rm -rf tmp\n",
    "        return\n",
    "    \n",
    "    def get_model_online(self,X_train,X_valid,y_train,y_valid,X_test=None):\n",
    "\n",
    "        ros = SMOTETomek(random_state=0)\n",
    "        X_train,y_train = ros.fit_resample(X_train,y_train)\n",
    "\n",
    "        if X_train.shape[1]<self.default_pca_components:\n",
    "            self.pca_components = int(0.75*X_train.shape[1])\n",
    "        else:\n",
    "            self.pca_components=self.default_pca_components\n",
    "            \n",
    "        if self.test:\n",
    "            obj = self.object_map[self.model](X_train,X_valid,y_train,y_valid,X_test)\n",
    "        else:\n",
    "            obj = self.object_map[self.model](X_train,X_valid,y_train,y_valid)\n",
    "        return obj\n",
    "    \n",
    "    \n",
    "    def get_model_offline(self,featfilename,testfeatfilename=None):\n",
    "        \n",
    "        df1 = pd.read_csv(featfilename,header=None)\n",
    "        df2 = pd.read_csv(self.label_file,header=None)\n",
    "        df_feat = df1.merge(df2,on=0).set_index(0)\n",
    "        df_feat_train = df_feat.loc[self.enz_train]\n",
    "        df_feat_valid = df_feat.loc[self.enz_valid]\n",
    "        X_train_feat,y_train_feat = df_feat_train.iloc[:,0:-1].values,df_feat_train.iloc[:,-1].values\n",
    "        X_valid_feat,y_valid_feat = df_feat_valid.iloc[:,0:-1].values,df_feat_valid.iloc[:,-1].values\n",
    "        \n",
    "        ros = SMOTETomek(random_state=0)\n",
    "        X_train_feat,y_train_feat = ros.fit_resample(X_train_feat,y_train_feat)\n",
    "\n",
    "        if X_train_feat.shape[1]<self.default_pca_components:\n",
    "            self.pca_components = int(0.75*X_train_feat.shape[1])\n",
    "        else:\n",
    "            self.pca_components=self.default_pca_components\n",
    "            \n",
    "        if self.test:\n",
    "            df_feat_test = pd.read_csv(testfeatfilename,header=None).set_index(0)\n",
    "            X_test_feat = df_feat_test.loc[self.testenz_names].values\n",
    "            if X_train_feat.shape[1] != X_test_feat.shape[1]:\n",
    "                print(featfilename)\n",
    "            obj = self.object_map[self.model](X_train_feat,X_valid_feat,y_train_feat,y_valid_feat,X_test_feat)\n",
    "        else:\n",
    "            obj = self.object_map[self.model](X_train_feat,X_valid_feat,y_train_feat,y_valid_feat)\n",
    "            \n",
    "        pattern = re.compile('.+/(.+)\\.csv\\.gz$')\n",
    "        m = pattern.match(featfilename)\n",
    "        feat_name = m.group(1)\n",
    "        self.write_model_stats(feat_name,obj)\n",
    "        \n",
    "        \n",
    "        return obj\n",
    "    \n",
    "        \n",
    "    def select_top_models(self,Os):\n",
    "        o_valid_accs = [o.acc_valid for o in Os] if self.test else [o.acc_train for o in Os] \n",
    "        sorted_idx = np.argsort(o_valid_accs)[::-1]\n",
    "        best_idx = sorted_idx[:self.n_models]\n",
    "        return best_idx,np.array(Os)[best_idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40min 25s, sys: 15 s, total: 40min 40s\n",
      "Wall time: 44min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__=='__main__':\n",
    "    enz_file = '../data/enz_sequence.csv'\n",
    "    label_file = '../data/enz_labels.csv'\n",
    "    \n",
    "\n",
    "\n",
    "    # Feature files for iFeature, pssmMethods \n",
    "    ifeatdatadir = '../featEngg/offline/ifeatMethods/data/featvec/trainfiles/'\n",
    "    pssmdatadir = '../featEngg/offline/pssmMethods/data/featvec/trainfiles/'\n",
    "    \n",
    "    trainfeatdirs = [ifeatdatadir,pssmdatadir]\n",
    "    \n",
    "    ec = EClassification(enz_file,None,label_file,trainfeatdirs,None,model='SVM',validation_fraction=0.5,pca_components=175,n_models=17)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6062313556513093"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec.en.acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accs =  [so.acc_valid for so in np.array(ec.objects)[ec.best_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accs =  [so.acc_train for so in np.array(ec.objects)[ec.best_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9981313400961025, 0.9650852878464818, 0.9883404064780009)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train_accs),min(train_accs),np.mean(train_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6158435531985416, 0.5575074577394763, 0.580826298036616)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_accs),min(test_accs),np.mean(test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44011976047904194"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec.precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([ 334, 2683]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ec.en.preds,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([1148, 1869]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ec.y_valid,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['KSCTriad', 'CTriad', 'DPC', 'DDE', 'Moran', 'CKSAAP', 'Geary',\n",
       "       'NMBroto', 's_fpssm', 'TPC', 'rpm_pssm', 'smoothed_pssm', 'GTPC',\n",
       "       'pssm_composition', 'ab_pssm', 'pssm_ac', 'CTDD'], dtype='<U24')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec.best_model_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
