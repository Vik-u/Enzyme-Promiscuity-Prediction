{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import starmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Sequence Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqfile = '../data/enz_sequence.csv'\n",
    "\n",
    "enzyme_names = []\n",
    "X_raw = []\n",
    "\n",
    "with open(seqfile,'rt') as f:\n",
    "    for lines in f:\n",
    "        val = lines.strip().split(',')\n",
    "        enzyme_names.append(val[0])\n",
    "        X_raw.append(val[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get integer encoded sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAs = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "         'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "\n",
    "AAdict = {aa:i+1 for i,aa in enumerate(AAs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_integer_features(seq):\n",
    "    seq_int = []\n",
    "    for res in seq:\n",
    "        seq_int.append(AAdict[res])\n",
    "    return seq_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_int_enc = list(map(get_integer_features,X_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trim/Pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(seq,length):\n",
    "    '''pads a variable length sequence into a sequence of length {length} with zeros'''\n",
    "    seq_length = len(seq)\n",
    "    delta = length - seq_length\n",
    "    pre_pad_length = delta//2\n",
    "    post_pad_length = delta - pre_pad_length\n",
    "    \n",
    "    pre_pad = np.zeros(pre_pad_length)\n",
    "    post_pad = np.zeros(post_pad_length)\n",
    "    \n",
    "    seq = np.array(seq)\n",
    "    \n",
    "    seq = np.insert(seq,0,pre_pad)\n",
    "    \n",
    "    seq = np.append(seq,post_pad)\n",
    "    return seq\n",
    "\n",
    "\n",
    "def trim_sequence(seq,length):\n",
    "    '''trims a variable length sequence into a sequence of equal length'''\n",
    "    seq_length = len(seq)\n",
    "    delta = seq_length - length\n",
    "    pre_trim_length = delta//2\n",
    "    post_trim_length = delta - pre_trim_length\n",
    "    \n",
    "    seq = np.array(seq)\n",
    "    \n",
    "    return seq[pre_trim_length:seq_length-post_trim_length]\n",
    "\n",
    "\n",
    "def process_sequence(seq,length):\n",
    "    '''modifies a sequence of variable length into an user-defined length'''\n",
    "    seq_length = len(seq)\n",
    "    if seq_length == length:\n",
    "        return np.array(seq)\n",
    "    \n",
    "    elif seq_length<length:\n",
    "        return pad_sequence(seq,length)\n",
    "    \n",
    "    elif seq_length>length:\n",
    "        return trim_sequence(seq,length)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get median length of all seq\n",
    "all_seq_length = list(map(len,X_int_enc))\n",
    "median_len = np.median(all_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "argument_iter = zip(X_int_enc,[int(median_len) for i in range(len(X_int_enc))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_int_samelen = list(starmap(process_sequence,argument_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_int_enc = np.array(X_int_samelen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6033, 408)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_int_enc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform to Matrix- OHE\n",
    "\n",
    "Rows: AminoAcid Type\n",
    "Cols: 1 if the amino acid corresponding to that row is present in that particular position in the sequence, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_helper(idx):\n",
    "    arr = np.zeros((len(AAdict)+1,1))\n",
    "    arr[int(idx)] = 1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_seq(sequence):\n",
    "    return np.concatenate(tuple(map(transform_helper, sequence)), axis=1)\n",
    "\n",
    "def transform(sequences):\n",
    "    return list(map(transform_seq, sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(transform(X_int_enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelfile = '../data/enz_labels.csv'\n",
    "\n",
    "enzyme_namesy = []\n",
    "y_raw = []\n",
    "\n",
    "with open(labelfile,'rt') as f:\n",
    "    for lines in f:\n",
    "        val = lines.strip().split(',')\n",
    "        enzyme_namesy.append(val[0])\n",
    "        y_raw.append(int(val[1]))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert enzyme_names == enzyme_namesy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "enzyme_names = np.array(enzyme_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make train test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0_idx = np.argwhere(y==0).flatten()\n",
    "y1_idx = np.argwhere(y==1).flatten()\n",
    "\n",
    "train0_idx = np.random.choice(y0_idx,size=int(0.75*len(y0_idx)),replace=False)\n",
    "train1_idx = np.random.choice(y1_idx,size=int(0.45*len(y1_idx)),replace=False)\n",
    "\n",
    "valid0_idx = np.array([i for i in y0_idx if i not in train0_idx])\n",
    "valid1_idx = np.array([i for i in y1_idx if i not in train1_idx])\n",
    "\n",
    "train_idx = np.append(train0_idx,train1_idx)\n",
    "valid_idx = np.append(valid0_idx,valid1_idx)\n",
    "\n",
    "np.random.shuffle(train_idx)\n",
    "np.random.shuffle(valid_idx)\n",
    "\n",
    "X_train,X_valid = X[train_idx],X[valid_idx]\n",
    "y_train,y_valid = y[train_idx],y[valid_idx]\n",
    "enz_train,enz_valid = enzyme_names[train_idx],enzyme_names[valid_idx]\n",
    "\n",
    "assert len(enz_train) + len(enz_valid) == len(enzyme_names)\n",
    "assert len(X_train) + len(X_valid) == len(X)\n",
    "assert len(y_train) + len(y_valid) == len(y)\n",
    "\n",
    "len_tr = X_train.shape[0]\n",
    "len_va = X_valid.shape[0]\n",
    "\n",
    "X_train = X_train.reshape((len_tr,1,21,408)).astype('float32')\n",
    "X_valid = X_valid.reshape((len_va,1,21,408)).astype('float32')\n",
    "y_train = y_train.reshape(-1,1).astype('float32')\n",
    "y_valid = y_valid.reshape(-1,1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3391, 1, 21, 408)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = []\n",
    "for i in range(len(X_train)):\n",
    "    trainset.append([X_train[i],y_train[i]])\n",
    "\n",
    "validset = []\n",
    "for i in range(len(X_valid)):\n",
    "    validset.append([X_valid[i],y_valid[i]])\n",
    "    \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=500,\n",
    "                                          shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(D_CNN, self).__init__()\n",
    "\n",
    "        self.convlayers = nn.Sequential(\n",
    "          nn.Conv2d(in_channels = 1, out_channels = 21, kernel_size = (1, 25), stride = 1, padding = 0, dilation=1),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(in_channels = 3, out_channels = 6, kernel_size = (3, 15), stride = 1, padding = 0, dilation=2),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(in_channels = 6, out_channels = 9, kernel_size = (3, 15), stride = 1, padding = 0, dilation=2),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(in_channels = 9, out_channels = 9, kernel_size = (3, 15), stride = 1, padding = 0, dilation=2),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(in_channels = 9, out_channels = 9, kernel_size = (3, 15), stride = 1, padding = 0, dilation=2),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(in_channels = 9, out_channels = 9, kernel_size = (3, 15), stride = 1, padding = 0, dilation=2),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(in_channels = 9, out_channels = 9, kernel_size = (3, 15), stride = 1, padding = 0, dilation=2),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(in_channels = 9, out_channels = 9, kernel_size = (3, 15), stride = 1, padding = 0, dilation=2),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(in_channels = 9, out_channels = 16, kernel_size = (3, 15), stride = 1, padding = 0, dilation=2),\n",
    "          nn.ReLU())\n",
    "        \n",
    "        self.fclayers = nn.Sequential(\n",
    "          nn.Linear(24960,1200),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(1200,184),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(184,10),nn.ReLU(),nn.Linear(10,1))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.convlayers(x)\n",
    "        x = x.view(-1,24960)\n",
    "        x = self.fclayers(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "d_cnn = D_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 3, 7])\n",
      "torch.Size([3])\n",
      "torch.Size([6, 3, 3, 15])\n",
      "torch.Size([6])\n",
      "torch.Size([9, 6, 3, 15])\n",
      "torch.Size([9])\n",
      "torch.Size([9, 9, 3, 15])\n",
      "torch.Size([9])\n",
      "torch.Size([9, 9, 3, 15])\n",
      "torch.Size([9])\n",
      "torch.Size([9, 9, 3, 15])\n",
      "torch.Size([9])\n",
      "torch.Size([9, 9, 3, 15])\n",
      "torch.Size([9])\n",
      "torch.Size([9, 9, 3, 15])\n",
      "torch.Size([9])\n",
      "torch.Size([16, 9, 3, 15])\n",
      "torch.Size([16])\n",
      "torch.Size([1200, 24960])\n",
      "torch.Size([1200])\n",
      "torch.Size([184, 1200])\n",
      "torch.Size([184])\n",
      "torch.Size([10, 184])\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for p in d_cnn.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "n_epochs = 20\n",
    "lr=0.001\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(d_cnn.parameters(), lr=lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lo(li,di,ks=25):\n",
    "    return li - di*(ks-1) -1 +1\n",
    "\n",
    "li = 8406\n",
    "dils = [0,2,4,6,8,16,32,64,128]\n",
    "\n",
    "for i in range(1,9):\n",
    "    dil = dils[i]\n",
    "    lo = get_lo(li,dil)\n",
    "    li = lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10830"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (1 x 284). Kernel size: (5 x 29). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-64647cafcbb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/deep-learning/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-f2578ca335d3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m24960\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfclayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/deep-learning/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/deep-learning/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/deep-learning/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/deep-learning/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/deep-learning/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (1 x 284). Kernel size: (5 x 29). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "for epoch in range(0,n_epochs+1):\n",
    "    \n",
    "    \n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ = data[0]\n",
    "        label = data[1]\n",
    "\n",
    "\n",
    "        ypred = d_cnn(input_)\n",
    "        \n",
    "        loss = criterion(ypred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.6f}\".format(loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = 0\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "for i,data in enumerate(validloader):\n",
    "    inputs, labels = data\n",
    "    \n",
    "    all_labels.extend(labels.flatten().detach().numpy())\n",
    "    \n",
    "    \n",
    "    outputs = d_cnn(inputs)    \n",
    "    num_correct += (outputs.round() == labels).sum()\n",
    "    \n",
    "    all_preds.extend(outputs.round().flatten().detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7865253595760787"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct.item()/(len(validset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.], dtype=float32), array([ 564, 2078]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(all_labels,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.], dtype=float32), array([2642]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(all_preds,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8805084745762711"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(all_labels,all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dzb5732/opt/anaconda3/envs/deep-learning/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(all_labels,all_preds,pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(all_labels,all_preds,pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
