{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcc3dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence similarity function\n",
    "from Bio import pairwise2\n",
    "from Bio.Align import substitution_matrices\n",
    "from itertools import starmap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Substrate similarity function\n",
    "from rdkit.DataStructs.cDataStructs import TanimotoSimilarity, BulkTanimotoSimilarity\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b3277f",
   "metadata": {},
   "source": [
    "# Tanimoto model write-up and steps\n",
    "\n",
    "Main idea: When compared to a given substrate, if a similar substrate interacts with an enzyme, then the given substrate will also interact with that and similar enzymes. \n",
    "\n",
    "Given an enzyme-substrate pair:\n",
    "\n",
    "- Get smiles notation of substrate \n",
    "- Select a substrate similarity threshold (Initialize and later optimize)\n",
    "- Detect substrates in the database which have Tanimoto similarity score with the given substrate greater than the selected substrate similarity threshold\n",
    "- Find enzymes known to react with those detected substrates\n",
    "- Select an enzyme similarity threshold (Initialize and later optimize)\n",
    "- Is the similarity score of the given enzyme with any of the found enzymes higher than the selected enzyme similarity threshold? \n",
    "    - Yes: Enzyme reacts with the given substrate.\n",
    "    - No: It does not react with the given substrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349ed99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tanimoto model\n",
    "\n",
    "class TanimotoInteractionPrediction:\n",
    "    \"\"\"Predict if an enzyme-substrate pair interacts based on their tanimoto similarity with\n",
    "    existing interacting enzyme-substrate pairs\"\"\"\n",
    "    def __init__(self, train_dti, train_enz, train_sub, \n",
    "                 valid_dti, valid_enz, valid_sub,\n",
    "                 enz_sim_thresh=1, subs_sim_thresh=0.33,\n",
    "                 with_label=True, start=0, end=250):\n",
    "        \n",
    "        # read training data\n",
    "        self.train_dti_df_ = self._read_csv(train_dti, columns=[0,1,2,3])\n",
    "        self.train_enz_df = self._read_csv(train_enz, columns=[1,2])\n",
    "        self.train_sub_df = self._read_csv(train_sub, columns=[1,2])\n",
    "        \n",
    "        # get rid of illegal sequences from training\n",
    "        illegal_proteins = list(self.train_enz_df.loc[self.train_enz_df.Sequence.str.contains(\"B|J|X|Z|O|U\", regex=True)].index)\n",
    "        self.train_dti_df = self.train_dti_df_.loc[~self.train_dti_df_.Protein_ID.isin(illegal_proteins)]\n",
    "        \n",
    "        # read validation data\n",
    "        if with_label:\n",
    "            self.valid_dti_df_ = self._read_csv(valid_dti, columns=[0,1,2,3]).iloc[start:end, :]\n",
    "        else:\n",
    "            self.valid_dti_df_ = self._read_csv(valid_dti, columns=[0,1,2]).iloc[start:end, :]\n",
    "            \n",
    "        self.valid_enz_df = self._read_csv(valid_enz, columns=[1,2])\n",
    "        self.valid_sub_df = self._read_csv(valid_sub, columns=[1,2])\n",
    "        \n",
    "        # get rid of illegal sequences from validation\n",
    "        illegal_proteins = list(self.valid_enz_df.loc[self.valid_enz_df.Sequence.str.contains(\"B|J|X|Z|O|U\", regex=True)].index)\n",
    "        self.valid_dti_df = self.valid_dti_df_.loc[~self.valid_dti_df_.Protein_ID.isin(illegal_proteins)]\n",
    "        \n",
    "        # modify training data to include only positive data\n",
    "        self.pos_train_dti_df = self.train_dti_df.loc[self.train_dti_df.Label==1].drop_duplicates()\n",
    "        \n",
    "        # define the thresholds\n",
    "        self.sst = subs_sim_thresh\n",
    "        self.est = enz_sim_thresh\n",
    "        \n",
    "        # store substrate similarity values for memoization \n",
    "        self.sub_sim_dict = dict()\n",
    "        self.enz_sim_dict = dict()\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    \n",
    "    def _read_csv(self, filename, columns):\n",
    "        df = pd.read_csv(filename, index_col=0, usecols=columns)\n",
    "        return df\n",
    "        \n",
    "    \n",
    "    def _get_protein_similarity(self, seq1, seq2, matrix=\"BLOSUM62\", gap_open=-10, gap_extend=-0.5):\n",
    "        mat = substitution_matrices.load(name=matrix)\n",
    "        alns = pairwise2.align.globalds(seq1, seq2, mat, gap_open, gap_extend)\n",
    "        top_aln = alns[0]\n",
    "        aln_human, aln_mouse, score, begin, end = top_aln\n",
    "        return score/len(seq1)\n",
    "\n",
    "\n",
    "    def _get_protein_bulk_similarity(self, seq1, list_of_seqs, matrix=\"BLOSUM62\", gap_open=-10, gap_extend=-0.5):\n",
    "        iterable = [(seq1, seq, matrix, gap_open, gap_extend) for seq in list_of_seqs]\n",
    "        scores = starmap(self._get_protein_similarity, iterable)\n",
    "        return np.array(list(scores))\n",
    "    \n",
    "    \n",
    "    # get smiles to mf function\n",
    "    def _smiles2fp(self, smiles):\n",
    "        # get the molecule from smiles\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        # get the molecular fingerprint as a 2048 length binary vector from molecule\n",
    "        mf = Chem.RDKFingerprint(mol)\n",
    "        return mf\n",
    "\n",
    "\n",
    "    # write tanimoto calculator function for two smiles\n",
    "    def _get_tanimoto_similarity(self, smiles1, smiles2):\n",
    "        mf1 = self._smiles2fp(smiles1)\n",
    "        mf2 = self._smiles2fp(smiles2)\n",
    "        Tanimoto_score = TanimotoSimilarity(mf1, mf2)\n",
    "        return Tanimoto_score\n",
    "\n",
    "\n",
    "    # write tanimoto calculator function for multiple mfs\n",
    "    def _get_bulk_tanimoto_similarity(self, smiles1, list_of_smiles):\n",
    "        mf1 = self._smiles2fp(smiles1)\n",
    "        mfs = list(map(self._smiles2fp, list_of_smiles))\n",
    "        Tanimoto_scores = BulkTanimotoSimilarity(mf1, mfs)\n",
    "        return np.array(Tanimoto_scores)\n",
    "    \n",
    "    \n",
    "    # predict single enzyme substrate pair\n",
    "    def predict_interaction(self, enz_id, sub_id):\n",
    "        \n",
    "        # get the substrate smiles and enzyme sequences from the validation df\n",
    "        sub1_smiles = self.valid_sub_df.loc[sub_id, \"smiles\"]\n",
    "        enz_seq = self.valid_enz_df.loc[enz_id, \"Sequence\"]\n",
    "        \n",
    "        # get smiles of existing substrates in the training df\n",
    "        subs_smiles = self.train_sub_df.values.flatten()\n",
    "        \n",
    "        \n",
    "        # memoization\n",
    "#         if sub1_smiles in self.sub_sim_dict:\n",
    "#             sim_subs = self.sub_sim_dict[sub1_smiles]\n",
    "#         else:\n",
    "#             # calculate bulk tanimoto similarity score\n",
    "#             tss = self._get_bulk_tanimoto_similarity(sub1_smiles, subs_smiles)\n",
    "#             # get substrates which have similarity score higher than threshold with the given substrate\n",
    "#             sim_subs = list(self.train_sub_df.iloc[np.where(tss>self.sst)[0], :].index)\n",
    "#             self.sub_sim_dict[sub1_smiles] = sim_subs\n",
    "        \n",
    "        \n",
    "        # calculate bulk tanimoto similarity score\n",
    "        tss = self._get_bulk_tanimoto_similarity(sub1_smiles, subs_smiles)\n",
    "        # get substrates which have similarity score higher than threshold with the given substrate\n",
    "        sim_subs = list(self.train_sub_df.iloc[np.where(tss>self.sst)[0], :].index)\n",
    "        \n",
    "        # get the enzymes which react with those substrates\n",
    "        react_enzs = self.pos_train_dti_df.loc[self.pos_train_dti_df.Compound_ID.isin(sim_subs)].Protein_ID.values\n",
    "        \n",
    "        # if one of the reacting enzymes have similarity value higher than protein similarity threshold flag \n",
    "        # as reacting and break the loop\n",
    "        for renz in react_enzs:\n",
    "            renz_seq = self.train_enz_df.loc[renz, \"Sequence\"]\n",
    "            \n",
    "            # memoization\n",
    "#             if enz_id in self.enz_sim_dict:\n",
    "#                 if renz in self.enz_sim_dict[enz_id]:\n",
    "#                     prot_sim_score = self.enz_sim_dict[enz_id][renz]\n",
    "#                 else:\n",
    "#                     prot_sim_score = self._get_protein_similarity(enz_seq, renz_seq)\n",
    "#                     self.enz_sim_dict[enz_id][renz] = prot_sim_score\n",
    "#                     if renz in self.enz_sim_dict:\n",
    "#                         self.enz_sim_dict[renz][enz_id] = prot_sim_score\n",
    "#                     else:\n",
    "#                         self.enz_sim_dict[renz] = dict()\n",
    "#                         self.enz_sim_dict[renz][enz_id] = prot_sim_score\n",
    "#             else:\n",
    "#                 prot_sim_score = self._get_protein_similarity(enz_seq, renz_seq)\n",
    "#                 self.enz_sim_dict[enz_id] = dict()\n",
    "#                 self.enz_sim_dict[enz_id][renz] = prot_sim_score\n",
    "#                 if renz in self.enz_sim_dict:\n",
    "#                     self.enz_sim_dict[renz][enz_id] = prot_sim_score\n",
    "#                 else:\n",
    "#                     self.enz_sim_dict[renz] = dict()\n",
    "#                     self.enz_sim_dict[renz][enz_id] = prot_sim_score\n",
    "\n",
    "            prot_sim_score = self._get_protein_similarity(enz_seq, renz_seq)\n",
    "            \n",
    "            if prot_sim_score>self.est:\n",
    "                return 1\n",
    "            \n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    def bulk_prediction(self):\n",
    "        pool = mp.Pool(mp.cpu_count())\n",
    "        iterable = list(zip(self.valid_dti_df.Protein_ID.values, self.valid_dti_df.Compound_ID.values))\n",
    "        results = pool.starmap(self.predict_interaction, iterable)\n",
    "        return results\n",
    "    \n",
    "    \n",
    "    def bulk_prediction_loop(self):\n",
    "        result_list = []\n",
    "        for enz, sub in zip(self.valid_dti_df.Protein_ID.values, self.valid_dti_df.Compound_ID.values):\n",
    "            pred = self.predict_interaction(enz, sub)\n",
    "            result_list.append(pred)\n",
    "        return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d69f94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training filenames\n",
    "tr_dti = \"../../../DeepConv-DTI/epp_examples/training_dataset/training_dti.csv\"\n",
    "tr_enz = \"../../../DeepConv-DTI/epp_examples/training_dataset/training_protein.csv\"\n",
    "tr_sub = \"../../../DeepConv-DTI/epp_examples/training_dataset/training_compound.csv\"\n",
    "\n",
    "# define validation filenames\n",
    "va_dti = \"../../../DeepConv-DTI/epp_examples/validation_dataset/validation_dti.csv\"\n",
    "va_enz = \"../../../DeepConv-DTI/epp_examples/validation_dataset/validation_protein.csv\"\n",
    "va_sub = \"../../../DeepConv-DTI/epp_examples/validation_dataset/validation_compound.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d1d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # training file arguments\n",
    "    parser.add_argument(\"tr_dti\", help=\"training file with enz-subs interactions\")\n",
    "    parser.add_argument(\"tr_enz\", help=\"training file with enz-sequence mappings\")\n",
    "    parser.add_argument(\"tr_sub\", help=\"training file with subs-fingerprint mappings\")\n",
    "\n",
    "    # validation file arguments\n",
    "    parser.add_argument(\"va_dti\", help=\"validation file with enz-subs interactions\")\n",
    "    parser.add_argument(\"va_enz\", help=\"validation file with enz-sequence mappings\")\n",
    "    parser.add_argument(\"va_sub\", help=\"validation file with subs-fingerprint mappings\")\n",
    "    \n",
    "    # optional arguments\n",
    "    parser.add_argument(\"-t\", \"--est\", help=\"enzyme similarity threshold\", type=float, default=1.0)\n",
    "    parser.add_argument(\"-T\", \"--sst\", help=\"substrate similarity threshold\", type=float, default=0.33)\n",
    "    \n",
    "    parser.add_argument(\"-l\", \"--labels\", help=\"True if validation file contains labels\", action=\"store_true\")\n",
    "    parser.add_argument(\"-s\", \"--start\", help=\"validation file prediction start\", type=int, default=0)\n",
    "    parser.add_argument(\"-e\", \"--end\", help=\"validation file prediction end\", type=int, default=250)\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # define class\n",
    "    tsm = TanimotoInteractionPrediction(args.tr_dti, args.tr_enz, args.tr_sub,\n",
    "                                        args.va_dti, args.va_enz, args.va_sub,\n",
    "                                        args.est, args.sst,\n",
    "                                        args.labels, args.start, args.end)\n",
    "    \n",
    "    # bulk predictions\n",
    "    res = tsm.bulk_prediction()\n",
    "    \n",
    "    \n",
    "    # store file based on label argument and start and end \n",
    "    if args.labels:\n",
    "        output_file = f\"./valid-results/valid_{args.start}_{args.end}.csv\"\n",
    "    else:\n",
    "        output_file = f\"./kegg-results/kegg_{args.start}_{args.end}.csv\"\n",
    "        \n",
    "    \n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(\",\".join(list(map(str, res))))\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "    \n",
    "    if args.labels:\n",
    "        with open(output_file, \"a\") as f:\n",
    "            f.write(\",\".join(list(map(str, tsm.valid_dti_df.Label.values))))\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f4123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
