{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dceea7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29bf3060",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prot_file = \"../../../DeepConv-DTI/epp_examples/training_dataset/training_protein.csv\"\n",
    "valid_prot_file = \"../../../DeepConv-DTI/epp_examples/validation_dataset/validation_protein.csv\" \n",
    "test_prot_file = \"../../../DeepConv-DTI/epp_examples/test_dataset/kegg_protein.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4536d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein pairwise similarity calculating function\n",
    "from Bio import pairwise2\n",
    "from Bio.Align import substitution_matrices\n",
    "from itertools import starmap\n",
    "\n",
    "\n",
    "def get_protein_similarity(seq1, seq2, matrix=\"BLOSUM62\", gap_open=-10, gap_extend=-0.5):\n",
    "    mat = substitution_matrices.load(name=matrix)\n",
    "    alns = pairwise2.align.globalds(seq1, seq2, mat, gap_open, gap_extend)\n",
    "    top_aln = alns[0]\n",
    "    aln_human, aln_mouse, score, begin, end = top_aln\n",
    "    return score/len(seq1)\n",
    "\n",
    "\n",
    "def get_protein_bulk_similarity(seq1, list_of_seqs, matrix=\"BLOSUM62\", gap_open=-10, gap_extend=-0.5):\n",
    "    iterable = [(seq1, seq, matrix, gap_open, gap_extend) for seq in list_of_seqs]\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    scores = pool.starmap(get_protein_similarity, iterable)\n",
    "    return np.array(list(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14806121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to map 1st validation protein similarity to all others\n",
    "\n",
    "def create_prot_sim_dict(train_file, valid_file, output_file):\n",
    "    df_train_ = pd.read_csv(train_file, usecols=[1,2], index_col=0)\n",
    "    df_valid_ = pd.read_csv(valid_file, usecols=[1,2], index_col=0).iloc[:2, ]\n",
    "    \n",
    "    # get rid of illegal sequences\n",
    "    illegal_proteins = list(df_train_.loc[df_train_.Sequence.str.contains(\"B|J|X|Z|O|U\", regex=True)].index)\n",
    "    df_train = df_train_.loc[~df_train_.index.isin(illegal_proteins)]\n",
    "    \n",
    "    illegal_proteins_valid = list(df_valid_.loc[df_valid_.Sequence.str.contains(\"B|J|X|Z|O|U\", regex=True)].index)\n",
    "    df_valid = df_valid_.loc[~df_valid_.index.isin(illegal_proteins_valid)]\n",
    "    \n",
    "    # creating the dictionary\n",
    "    all_train_prots = list(df_train.index)\n",
    "    all_train_seq = df_train.values.flatten()\n",
    "    prot_sim_dict = dict()\n",
    "\n",
    "    for prot, seq_info in tqdm(df_valid.iterrows()):\n",
    "        seq = seq_info.values[0]\n",
    "        sim_scores = get_protein_bulk_similarity(seq, all_train_seq)\n",
    "        prot_sim_dict[prot] = {train_prot:sim_score for train_prot,sim_score in zip(all_train_prots, sim_scores)}\n",
    "    \n",
    "    # saving the dictionary as json\n",
    "    with open(output_file, 'w') as fp:\n",
    "        json.dump(prot_sim_dict, fp, indent=4)\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9380dc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [53:38, 1609.50s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'prot_sim_valid_dict.json'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_prot_sim_dict(train_prot_file, valid_prot_file, \"prot_sim_valid_dict.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661bea96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
